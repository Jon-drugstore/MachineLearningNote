# <center>SVM</center>

<br></br>



## 线性分类器起源
----
给定数据点，属于两类，找到一个线性分类器把数据分成两类。

![](./Images/svm9.png)

用一条直线把空间切割开，左边点属于类别-1（三角），右边点属于类别1（方块）。即，由$$X_1$$和$$X_2$$组成的二维空间，直线方程是$$X_1+X_2 = 1$$，向量符号表示为$$[1,1]^{T}[X_1,X_2]-1=0$$。点$$x$$在左边指，当把$$x$$放入方程左边，计算结果小于0。

在二维空间，用一条直线可把空间分割。三维空间需一个平面把空间切成两半，方程是$$X_1+X_2+X_3=1$$，即$$[1,1,1]^{T}[X_1,X_2,X_3]-1=0$$。

![](./Images/svm10.png)

依此类推，高维空间需$$n-1维$$超平面将空间切割。抽象归纳如下：

$$x$$表示数据点，$$y$$表示类别（1或-1，代表两个类），线性分类器学习目标是要在$$n$$维数据空间中找到一个超平面（hyper plane），把空间切割开，超平面方程表示为：

$$
W^{T}X+b=0
$$

<br></br>



## 感知器模型和逻辑回归
----
常见线性分类器有感知器模型和逻辑回归。感知器模型直接分好类。有时，除了知道分类结果，还希望知道分类器对这次分类成功概率。逻辑回归就可以。

逻辑回归将线性分类器超平面方程计算结果通过Logistic函数从正负无穷映射到0或1。映射结果可认为是分类器将$$x$$判定为类别1的概率。

举例，感知器天气预报只会告诉明天下雨（$$y=1$$）或不下（$$y=-1$$）；逻辑回归天气预报能告诉明天有90%概率要下雨。

逻辑回归公式是$$g(z)=\frac{1}{1+e^{-z}}$$：

![](./Images/svm11.png)

感知器模型中，将特征代入判别方程，如果得-3，可判定类别是-1。逻辑回归中，将-3代入$$g(z)$$，就知道该数据属于类别1概率是0.05。

<br></br>



## SVM
----
在多维空间下，用一个超平面可把数据分为两类。这个超平面称为分离超平面。但分离超平面有很多个，用哪个呢？

![](./Images/svm1.jpg)

训练数据中，每个元素距离分离超平面都有一个距离。在添加超平面时，尽可能使最靠近分离超平面那个元素与超平面距离变大。这样，加入新数据时，准确分类概率会最大化。感知器模型和逻辑回归都不能完成这个工作，而SVM就可以。

对于支持向量机，数据点若是$$p$$维向量，用$$p-1$$维超平面分开这些点。但可能有许多超平面可把数据分类。最佳超平面合理选择是以最大间隔把两个类分开的超平面。因此，SVM选择能使离超平面最近的数据点的到超平面距离最大的超平面。

> 这条直线/超平面位置由距离最近的几个点决定的，其它样本点没有关系。即，该直线/超平面由几个样本点支撑（Support），而每个样本点是一个多维向量（Vector），并且算法本质上是分类器（Classification Machine），所以叫Support Vector Machines。

SVM的模型:

* 线性可分SVM
    
    当训练数据线性可分，通过硬间隔（hard margin）最大化可学习得到一个线性分类器，即硬间隔SVM。

* 线性SVM

    当训练数据不能线性可分但近似线性可分时，通过软间隔（soft margin）最大化也可学到一个线性分类器，即软间隔SVM。

* 非线性SVM

    当训练数据线性不可分，通过核技巧（kernel trick）和软间隔最大化，可以学到一个非线性SVM。

<br></br>



## 优缺点
----
优点：
* 由于SVM是凸优化问题，求得的解一定是全局最优。
* 不仅适用于线性线性问题还适用于非线性问题（用核技巧）。
* 高维样本空间数据也能用SVM。因为数据集复杂度只取决于支持向量而不是数据集维度，这在某种意义上避免了维数灾难。
* 理论基础完善，而神经网络像黑盒子。
* 决策函数（称为支持向量）只使用训练样本点一小部分，内存比较有效率。

缺点：
* 二次规划问题求解涉及$$m$$阶矩阵计算，其中$$m$$为样本个数。因此SVM不适用于超大数据集。(SMO算法可缓解这个问题)
* 只适用二分类问题。
* 不支持直接概率评估，而是通过代价昂贵的五折交叉样本计算而来

<br></br>



## 多分类
----
SVM中的多分类的问题可通过DAG SVM解决：

![](./Images/dag_svm.gif)

分类时，先问分类器“1对5”（意思是它能回答“是第1类还是第5类”）。如果5，往左走，再问“2对5”分类器。如果还是“5”，继续左走。这样下去，可得到分类结果。时间复杂度最坏是$$O(N^3)$$。
